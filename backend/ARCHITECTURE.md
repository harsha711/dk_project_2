# ğŸ—ï¸ Architecture Documentation

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Dental AI Platform                       â”‚
â”‚                    (Gradio Web Interface)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚  Tab 1  â”‚         â”‚  Tab 2  â”‚
   â”‚ Vision  â”‚         â”‚  Chat   â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                   â”‚
        â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vision APIs   â”‚    â”‚   Chat APIs (Async)    â”‚
â”‚                â”‚    â”‚                        â”‚
â”‚  - GPT-4o-V    â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  - Gemini-V    â”‚    â”‚  â”‚  OpenAI GPT-4o   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
        â”‚             â”‚  â”‚  Google Gemini   â”‚  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚ Image Utils    â”‚    â”‚  â”‚  Groq Llama3     â”‚  â”‚
â”‚                â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚ - Parse JSON   â”‚    â”‚    (Parallel Exec)     â”‚
â”‚ - Draw Boxes   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ - Annotate     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Breakdown

### 1. Main Application (`dental_ai_app.py`)

**Purpose:** Gradio UI orchestration

```python
Responsibilities:
â”œâ”€â”€ Define UI layout (tabs, buttons, inputs)
â”œâ”€â”€ Handle user events (clicks, uploads)
â”œâ”€â”€ Route requests to appropriate modules
â””â”€â”€ Display results to user
```

**Key Functions:**
- `process_xray(image, model_choice)` â†’ Processes X-ray uploads
- `chat_with_all_models(query)` â†’ Handles multi-model chat

**Gradio Components Used:**
- `gr.Image()` - X-ray upload
- `gr.Textbox()` - Chat input
- `gr.Markdown()` - Response display
- `gr.Radio()` - Model selection
- `gr.Button()` - Action triggers
- `gr.Tabs()` - Tab organization

---

### 2. API Utilities (`api_utils.py`)

**Purpose:** Abstract API interactions

```python
Vision APIs:
â”œâ”€â”€ analyze_xray_gpt4v()
â”‚   â”œâ”€â”€ Encode image to base64
â”‚   â”œâ”€â”€ Call OpenAI vision API
â”‚   â””â”€â”€ Return structured response
â”‚
â””â”€â”€ analyze_xray_gemini()
    â”œâ”€â”€ Convert PIL image
    â”œâ”€â”€ Call Gemini vision API
    â””â”€â”€ Return structured response

Chat APIs (Async):
â”œâ”€â”€ chat_openai_async()
â”‚   â””â”€â”€ Run in thread pool executor
â”‚
â”œâ”€â”€ chat_gemini_async()
â”‚   â””â”€â”€ Run in thread pool executor
â”‚
â”œâ”€â”€ chat_groq_async()
â”‚   â””â”€â”€ Run in thread pool executor
â”‚
â””â”€â”€ chat_all_models()
    â”œâ”€â”€ Create async tasks
    â”œâ”€â”€ asyncio.gather() - parallel execution
    â””â”€â”€ Return all results
```

**Why Async?**
```
Sequential:  [GPT-4o: 5s] â†’ [Gemini: 3s] â†’ [Groq: 2s] = 10s total
Parallel:    [GPT-4o: 5s]
             [Gemini: 3s]  } = 5s total (max of all)
             [Groq: 2s]
```

**Error Handling:**
```python
try:
    response = api_call()
    return {"success": True, "response": data}
except Exception as e:
    return {"success": False, "error": str(e)}
```

---

### 3. Image Utilities (`image_utils.py`)

**Purpose:** Image processing & annotation

```python
Image Pipeline:
â”œâ”€â”€ parse_vision_response()
â”‚   â”œâ”€â”€ Extract JSON from markdown
â”‚   â”œâ”€â”€ Handle code blocks
â”‚   â””â”€â”€ Parse to dict
â”‚
â”œâ”€â”€ draw_bounding_boxes()
â”‚   â”œâ”€â”€ Convert % coords to pixels
â”‚   â”œâ”€â”€ Draw rectangles (PIL)
â”‚   â”œâ”€â”€ Add labels
â”‚   â””â”€â”€ Color code by position
â”‚
â””â”€â”€ create_side_by_side_comparison()
    â”œâ”€â”€ Resize images to match height
    â”œâ”€â”€ Combine horizontally
    â””â”€â”€ Add labels
```

**Color Mapping:**
```python
{
    "upper-left": "#FF6B6B",    # Red
    "upper-right": "#4ECDC4",   # Teal
    "lower-left": "#FFE66D",    # Yellow
    "lower-right": "#95E1D3"    # Mint
}
```

**Coordinate System:**
```
Vision APIs return: [x_min%, y_min%, x_max%, y_max%]
Convert to pixels: coord * image_dimension

Example:
  Image: 1000x800 pixels
  Bbox: [0.6, 0.7, 0.85, 0.95]
  â†’     [600, 560, 850, 760] pixels
```

---

## Data Flow Diagrams

### Tab 1: Wisdom Tooth Detection Flow

```
User Action
    â”‚
    â”œâ”€â†’ Upload Image (PNG/JPG)
    â”‚       â”‚
    â”‚       â†“
    â”‚   PIL.Image object
    â”‚       â”‚
    â”œâ”€â†’ Select Model (Radio)
    â”‚       â”‚
    â”œâ”€â†’ Click "Analyze"
    â”‚       â”‚
    â”‚       â†“
    â”œâ”€â†’ process_xray()
            â”‚
            â”œâ”€â†’ if GPT-4o Vision:
            â”‚       â”‚
            â”‚       â”œâ”€â†’ encode_image_to_base64()
            â”‚       â”‚
            â”‚       â”œâ”€â†’ analyze_xray_gpt4v()
            â”‚       â”‚       â”‚
            â”‚       â”‚       â”œâ”€â†’ OpenAI API call
            â”‚       â”‚       â”‚
            â”‚       â”‚       â””â”€â†’ Return JSON response
            â”‚       â”‚
            â”‚   or Gemini Vision:
            â”‚       â”‚
            â”‚       â”œâ”€â†’ analyze_xray_gemini()
            â”‚               â”‚
            â”‚               â”œâ”€â†’ Google Gemini API call
            â”‚               â”‚
            â”‚               â””â”€â†’ Return JSON response
            â”‚
            â”œâ”€â†’ parse_vision_response()
            â”‚       â”‚
            â”‚       â”œâ”€â†’ Extract JSON from markdown
            â”‚       â”‚
            â”‚       â””â”€â†’ Parse teeth_found[]
            â”‚
            â”œâ”€â†’ draw_bounding_boxes()
            â”‚       â”‚
            â”‚       â”œâ”€â†’ For each tooth:
            â”‚       â”‚       â”œâ”€â†’ Convert % to pixels
            â”‚       â”‚       â”œâ”€â†’ Draw rectangle
            â”‚       â”‚       â””â”€â†’ Add label
            â”‚       â”‚
            â”‚       â””â”€â†’ Return annotated image
            â”‚
            â””â”€â†’ Format analysis text
                    â”‚
                    â””â”€â†’ Display results
```

### Tab 2: Multi-Model Chat Flow

```
User Action
    â”‚
    â”œâ”€â†’ Type Question
    â”‚       â”‚
    â”œâ”€â†’ Click "Ask All Models"
    â”‚       â”‚
    â”‚       â†“
    â”œâ”€â†’ chat_with_all_models()
            â”‚
            â”œâ”€â†’ Create asyncio event loop
            â”‚
            â”œâ”€â†’ chat_all_models() [ASYNC]
            â”‚       â”‚
            â”‚       â”œâ”€â†’ Create 3 async tasks:
            â”‚       â”‚       â”‚
            â”‚       â”‚       â”œâ”€â†’ Task 1: chat_openai_async()
            â”‚       â”‚       â”‚       â”‚
            â”‚       â”‚       â”‚       â””â”€â†’ GPT-4o API (in thread pool)
            â”‚       â”‚       â”‚
            â”‚       â”‚       â”œâ”€â†’ Task 2: chat_gemini_async()
            â”‚       â”‚       â”‚       â”‚
            â”‚       â”‚       â”‚       â””â”€â†’ Gemini API (in thread pool)
            â”‚       â”‚       â”‚
            â”‚       â”‚       â””â”€â†’ Task 3: chat_groq_async()
            â”‚       â”‚               â”‚
            â”‚       â”‚               â””â”€â†’ Groq API (in thread pool)
            â”‚       â”‚
            â”‚       â”œâ”€â†’ await asyncio.gather(*tasks)
            â”‚       â”‚       â”‚
            â”‚       â”‚       â””â”€â†’ Wait for ALL to complete
            â”‚       â”‚
            â”‚       â””â”€â†’ Return (result1, result2, result3)
            â”‚
            â”œâ”€â†’ Format responses with âœ…/âŒ
            â”‚
            â””â”€â†’ Display in 3 columns
```

---

## API Integration Details

### OpenAI GPT-4o Vision

**Endpoint:** `chat.completions.create`
**Input Format:**
```python
{
    "model": "gpt-4o",
    "messages": [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "prompt"},
                {"type": "image_url", "image_url": {
                    "url": "data:image/png;base64,..."
                }}
            ]
        }
    ]
}
```

**Response:** JSON with text content

---

### Google Gemini Vision

**Endpoint:** `GenerativeModel.generate_content`
**Input Format:**
```python
model = genai.GenerativeModel('gemini-1.5-flash')
response = model.generate_content([prompt_text, pil_image])
```

**Response:** `response.text` contains analysis

---

### Chat APIs (All)

**Common Pattern:**
```python
messages = [
    {"role": "system", "content": "You are helpful"},
    {"role": "user", "content": query}
]

response = client.chat.completions.create(
    model=model_name,
    messages=messages,
    max_tokens=500,
    temperature=0.7
)

answer = response.choices[0].message.content
```

---

## Performance Optimization

### 1. Parallel API Calls

**Implementation:**
```python
async def chat_all_models():
    tasks = [
        chat_openai_async(query),
        chat_gemini_async(query),
        chat_groq_async(query)
    ]
    # All run concurrently
    results = await asyncio.gather(*tasks)
    return results
```

**Benefit:** 3x faster than sequential

---

### 2. Thread Pool for Sync APIs

**Problem:** OpenAI/Groq SDKs are synchronous
**Solution:** Run in executor

```python
async def chat_openai_async():
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(
        None,  # Default thread pool
        lambda: openai_client.chat.completions.create(...)
    )
    return result
```

---

### 3. Image Encoding Cache

**Future Enhancement:**
```python
@lru_cache(maxsize=128)
def encode_image_to_base64(image_hash):
    # Cache encoded images
    pass
```

---

## Error Handling Strategy

### Layer 1: API Call Level
```python
try:
    response = api_call()
    return {"success": True, "response": data}
except APIError as e:
    return {"success": False, "error": f"API Error: {e}"}
except Exception as e:
    return {"success": False, "error": f"Unexpected: {e}"}
```

### Layer 2: Processing Level
```python
if not result["success"]:
    return None, f"âŒ Error: {result['error']}"
```

### Layer 3: UI Level
```python
# Gradio displays error message
# User sees friendly error without crash
```

---

## Security Considerations

### 1. API Key Management
```
âœ… Load from .env file
âœ… Never log API keys
âœ… Never expose in error messages
âœ… .gitignore prevents commits
```

### 2. Input Validation
```python
if not message.strip():
    return "Please enter a message"

if not image:
    return None, "Please upload image"
```

### 3. Rate Limiting (TODO)
```python
# Future enhancement
from gradio.utils import rate_limit

@rate_limit(max_calls=10, period=60)
def process_xray():
    pass
```

---

## Testing Strategy

### 1. Unit Tests (test_example.py)
```python
âœ“ Test API key loading
âœ“ Test client initialization
âœ“ Test simple API calls
```

### 2. Integration Tests (Manual)
```
âœ“ Upload image â†’ verify annotation
âœ“ Ask question â†’ verify 3 responses
âœ“ Test error handling (invalid image)
```

### 3. Performance Tests
```
âœ“ Measure parallel vs sequential
âœ“ Check response times
âœ“ Monitor API usage
```

---

## Deployment Architecture

### Local Development
```
User Browser
    â†“
localhost:7860 (Gradio)
    â†“
Local Python Process
    â†“
External APIs
```

### Production (Example)
```
Users
    â†“
HTTPS/SSL
    â†“
Nginx Reverse Proxy
    â†“
Gunicorn + Gradio
    â†“
Redis (Cache)
    â†“
External APIs
```

---

## Extension Points

### Add New Vision Model
1. Create `analyze_xray_newmodel()` in `api_utils.py`
2. Add to model selector in `dental_ai_app.py`
3. Update UI choices

### Add New Chat Model
1. Create `chat_newmodel_async()` in `api_utils.py`
2. Add to `chat_all_models()` tasks
3. Add output column in UI

### Add New Feature Tab
1. Create new tab in `dental_ai_app.py`
2. Add processing function
3. Connect UI components

---

## Dependencies Graph

```
dental_ai_app.py
    â”œâ”€â†’ gradio
    â”œâ”€â†’ dotenv
    â”œâ”€â†’ PIL
    â”œâ”€â†’ api_utils
    â”‚       â”œâ”€â†’ openai
    â”‚       â”œâ”€â†’ groq
    â”‚       â”œâ”€â†’ google.generativeai
    â”‚       â””â”€â†’ asyncio
    â””â”€â†’ image_utils
            â”œâ”€â†’ PIL
            â”œâ”€â†’ cv2
            â”œâ”€â†’ numpy
            â””â”€â†’ json
```

---

## File Size & Complexity

| File | Lines | Functions | Complexity |
|------|-------|-----------|------------|
| dental_ai_app.py | ~300 | 3 | Medium |
| api_utils.py | ~240 | 9 | High |
| image_utils.py | ~180 | 5 | Medium |
| test_example.py | ~100 | 3 | Low |

**Total:** ~820 lines of production code

---

## Future Enhancements

1. **Response Caching** - Redis for repeated queries
2. **Batch Processing** - Multiple X-rays at once
3. **Export Reports** - PDF generation with results
4. **User Accounts** - Authentication & history
5. **Model Versioning** - A/B testing different models
6. **Analytics Dashboard** - Usage statistics
7. **Webhook Integration** - Connect to PACS systems
8. **Mobile App** - React Native wrapper

---

**Architecture designed for:**
- âœ… Modularity
- âœ… Scalability
- âœ… Maintainability
- âœ… Extensibility
- âœ… Performance
